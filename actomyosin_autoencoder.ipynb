{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actomyosin autoencoder code\n",
    "\n",
    "Liya Ding\n",
    "\n",
    "2024.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import actomyosin_data, plot64\n",
    "from model.autoencoder_64 import AE, VAE, CVAE\n",
    "from train_utils.autoencoder import AETrain, VAETrain, CVAETrain\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import os\n",
    "import warnings\n",
    "from itertools import cycle, islice\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave, imread\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "ae_type = 'AE'\n",
    "net_type = 'simple'\n",
    "latent_dim = 2\n",
    "num_epochs = 200\n",
    "learn_rate = 0.001\n",
    "train_buf = 12000\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/net/projects/CLS/actomyosin_dynamics/data/LifeAct-NMY2-GFP_patchsize_64_p95_all/NMY2_wt'\n",
    "patch_size = 64\n",
    "\n",
    "filenames = [x for x in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, x)) and ('.tif' in x)]\n",
    "filenames.sort()\n",
    "\n",
    "num_of_samples = min(len(filenames),train_buf)\n",
    "\n",
    "train_images = np.zeros([num_of_samples, patch_size, patch_size])\n",
    "train_labels= np.zeros([num_of_samples])\n",
    "\n",
    "for filename_ind in range(num_of_samples):\n",
    "    filename = filenames[filename_ind] \n",
    "             \n",
    "    train_img = tifffile.imread(os.path.join(data_dir,filename))\n",
    "    small_train_img = train_img/((train_img.max()))\n",
    "    train_images[filename_ind,:,:] = small_train_img\n",
    "    train_labels[filename_ind] = int(filename[1:5]+filename[6:10]+filename[11:15])\n",
    "\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 64, 64, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = train_buf\n",
    "BATCH_SIZE = batch_size\n",
    "\n",
    "train_dataset_image = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)\n",
    "train_dataset_label = tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE)\n",
    "train_dataset = tf.data.Dataset.zip((train_dataset_image, train_dataset_label)).shuffle(TRAIN_BUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AE(latent_dim, net_type=net_type)\n",
    "model_ID = ae_type+'_ld'+str(latent_dim)+'_nt'+net_type+'_bs'+ str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learn_rate)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    t = time.time()\n",
    "    last_loss = 0\n",
    "    for train_x, _ in train_dataset:\n",
    "        gradients, loss = AETrain.compute_gradients(model, train_x)\n",
    "        AETrain.apply_gradients(optimizer, gradients, model.trainable_variables)\n",
    "        last_loss = loss\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {}, Loss: {}, Remaining Time at This Epoch: {:.2f}'.format(\n",
    "            epoch, last_loss, time.time() - t\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "fig_dist = plt.figure(figsize=(8, 8))\n",
    "ax_dist = fig_dist.add_subplot(111)\n",
    "\n",
    "flag_sample = 1\n",
    "\n",
    "for x_input, y_input in train_dataset:\n",
    "    if flag_sample == 1:        \n",
    "        x_input_sample, y_input_sample = map(lambda x: x[:n], (x_input, y_input))\n",
    "        z = model.encode(x_input_sample).numpy()\n",
    "\n",
    "        fig1, axarr1 = plt.subplots(2, n, figsize=(n, 2))\n",
    "        x_input_sample = x_input_sample.numpy().reshape([n, 64, 64])\n",
    "        x_output = model.decode(z).numpy().reshape([n, 64, 64])\n",
    "\n",
    "        for i in range(n):\n",
    "            axarr1[0, i].axis('off')\n",
    "            axarr1[1, i].axis('off')\n",
    "            axarr1[0, i].imshow(x_input_sample[i],cmap=plt.cm.gray)\n",
    "            axarr1[1, i].imshow(x_output[i],cmap=plt.cm.gray)\n",
    "\n",
    "        fig1.savefig(\"results/\"+model_ID+\"_reconstruction.png\")\n",
    "        \n",
    "        z = model.encode(x_input)\n",
    "        Z_array = z.numpy()\n",
    "        Label_array = y_input\n",
    "        flag_sample = 0\n",
    "    else:\n",
    "        z = model.encode(x_input)\n",
    "        Z_array = np.concatenate((Z_array,z.numpy()), axis=0)\n",
    "        Label_array = np.concatenate((Label_array,y_input.numpy()), axis=0)\n",
    "        \n",
    "    \n",
    "ax_dist.scatter(Z_array[:,0], Z_array[:,1], color='blue',s=0.5)\n",
    "    \n",
    "fig_dist.savefig(\"results/\"+model_ID+\"_distribution.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
